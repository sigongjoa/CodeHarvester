from github_crawler import GithubCrawler
import json

def test_wanted_crawler():
    print("ğŸ” WantedImprovedCrawler í…ŒìŠ¤íŠ¸ ì‹œì‘")

    test_url = "https://www.wanted.co.kr/search?query=python"
    crawler = GithubCrawler()
    results = crawler.crawl(test_url, max_jobs=1)

    assert isinstance(results, list), "ê²°ê³¼ëŠ” ë¦¬ìŠ¤íŠ¸ì—¬ì•¼ í•©ë‹ˆë‹¤"
    assert len(results) > 0, "ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤"

    job = results[0]

    # í•„ìˆ˜ í•„ë“œ ê²€ì¦
    required_fields = ["company_name", "title", "description", "deadline", "experience", "location", "url", "crawled_at"]
    for field in required_fields:
        assert field in job, f"í•„ë“œ ëˆ„ë½: {field}"
        assert job[field], f"í•„ë“œ ê°’ì´ ë¹„ì–´ ìˆìŒ: {field}"

    print("âœ… í…ŒìŠ¤íŠ¸ í†µê³¼!")
    print(json.dumps(job, indent=2, ensure_ascii=False))

if __name__ == "__main__":
    test_wanted_crawler()

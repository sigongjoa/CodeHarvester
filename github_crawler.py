#!/usr/bin/env python3
"""
GitHub íŒŒì´ì¬ ì½”ë“œ í¬ë¡¤ëŸ¬

GitHubì—ì„œ íŒŒì´ì¬ ì½”ë“œë¥¼ ê²€ìƒ‰í•˜ê³  ë‹¤ìš´ë¡œë“œí•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.
í•™ìŠµìš©ìœ¼ë¡œ ì í•©í•œ ì½”ë“œë¥¼ í•„í„°ë§í•˜ëŠ” ê¸°ëŠ¥ì„ í¬í•¨í•©ë‹ˆë‹¤.
"""

import os
import base64
import time
import json
from datetime import datetime
from github import Github, RateLimitExceededException
import requests
from dotenv import load_dotenv
import os
from code_filter import CodeQualityFilter

load_dotenv()  # â¬…ï¸ .env íŒŒì¼ì„ ì½ì–´ì„œ os.environ ì— ë“±ë¡
token = os.getenv("GITHUB_TOKEN") 
print(f"[DEBUG] Loaded token: {token}")

class GitHubPythonCrawler:
    """GitHubì—ì„œ íŒŒì´ì¬ ì½”ë“œë¥¼ í¬ë¡¤ë§í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, token=None, output_dir="collected_code"):
        """
        í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”
        
        Args:
            token (str, optional): GitHub API í† í°. ì—†ìœ¼ë©´ ì œí•œëœ API ì‚¬ìš©
            output_dir (str, optional): ìˆ˜ì§‘ëœ ì½”ë“œë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬
        """
        self.github = Github(token) if token else Github()
        self.output_dir = output_dir
        self.metadata_file = os.path.join(output_dir, "metadata.json")
        self.quality_filter = CodeQualityFilter(metadata_file=self.metadata_file)
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(output_dir, exist_ok=True)
        
        # ë©”íƒ€ë°ì´í„° íŒŒì¼ ì´ˆê¸°í™”
        if not os.path.exists(self.metadata_file):
            with open(self.metadata_file, 'w', encoding='utf-8') as f:
                json.dump([], f)
                
    
    def search_repositories(self, query="language:python", sort="stars", 
                           order="desc", max_results=10):
        """
        GitHubì—ì„œ íŒŒì´ì¬ ì €ì¥ì†Œ ê²€ìƒ‰
        
        Args:
            query (str): ê²€ìƒ‰ ì¿¼ë¦¬
            sort (str): ì •ë ¬ ê¸°ì¤€ (stars, forks, updated)
            order (str): ì •ë ¬ ìˆœì„œ (desc, asc)
            max_results (int): ìµœëŒ€ ê²°ê³¼ ìˆ˜
            
        Returns:
            list: ê²€ìƒ‰ëœ ì €ì¥ì†Œ ëª©ë¡
        """
        print(f"GitHubì—ì„œ '{query}' ê²€ìƒ‰ ì¤‘...")
        try:
            repositories = self.github.search_repositories(
                query=query, sort=sort, order=order
            )
            
            results = []
            count = 0
            
            for repo in repositories:
                if count >= max_results:
                    break
                
                results.append({
                    'name': repo.name,
                    'full_name': repo.full_name,
                    'url': repo.html_url,
                    'description': repo.description,
                    'stars': repo.stargazers_count,
                    'forks': repo.forks_count,
                    'created_at': repo.created_at.isoformat(),
                    'updated_at': repo.updated_at.isoformat(),
                    'license': repo.license.name if repo.license else None
                })
                count += 1
                
            print(f"{len(results)}ê°œì˜ ì €ì¥ì†Œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
            return results
            
        except RateLimitExceededException:
            reset_time = self.github.get_rate_limit().core.reset
            current_time = datetime.utcnow()
            wait_time = (reset_time - current_time).total_seconds()
            print(f"API ì‚¬ìš©ëŸ‰ ì œí•œ ì´ˆê³¼. {wait_time:.0f}ì´ˆ í›„ì— ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
            return []
    
    def get_python_files(self, repo_name, max_files=None):
        """
        ì €ì¥ì†Œì—ì„œ ëª¨ë“  íŒŒì´ì¬ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        
        Args:
            repo_name (str): ì €ì¥ì†Œ ì´ë¦„ (ì˜ˆ: 'username/repo')
            max_files (int, optional): ìµœëŒ€ íŒŒì¼ ìˆ˜ (Noneì´ë©´ ëª¨ë“  íŒŒì¼)
            
        Returns:
            list: íŒŒì´ì¬ íŒŒì¼ ì •ë³´ ëª©ë¡
        """
        print(f"{repo_name} ì €ì¥ì†Œì—ì„œ íŒŒì´ì¬ íŒŒì¼ ê²€ìƒ‰ ì¤‘...")
        try:
            repo = self.github.get_repo(repo_name)
            contents = repo.get_contents("")
            python_files = []
            
            # ë””ë ‰í† ë¦¬ë¥¼ íƒìƒ‰í•˜ëŠ” ë™ì•ˆ ë°œìƒí•  ìˆ˜ ìˆëŠ” API ì œí•œì„ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ë³€ìˆ˜
            api_calls = 0
            last_api_call_time = time.time()
            
            while contents:
                if max_files is not None and len(python_files) >= max_files:
                    break
                    
                file_content = contents.pop(0)
                
                # API í˜¸ì¶œ ê´€ë¦¬
                api_calls += 1
                if api_calls % 10 == 0:  # 10ë²ˆì˜ API í˜¸ì¶œë§ˆë‹¤
                    current_time = time.time()
                    elapsed = current_time - last_api_call_time
                    if elapsed < 2:  # 2ì´ˆ ì´ë‚´ì— 10ë²ˆì˜ í˜¸ì¶œì´ ìˆì—ˆë‹¤ë©´
                        sleep_time = 2 - elapsed
                        print(f"API í˜¸ì¶œ ì œí•œ ë°©ì§€ë¥¼ ìœ„í•´ {sleep_time:.2f}ì´ˆ ëŒ€ê¸° ì¤‘...")
                        time.sleep(sleep_time)
                    last_api_call_time = time.time()
                
                try:
                    if file_content.type == "dir":
                        # ë””ë ‰í† ë¦¬ì¼ ê²½ìš° ì¶”ê°€ ì½˜í…ì¸  ê°€ì ¸ì˜¤ê¸°
                        print(f"ë””ë ‰í† ë¦¬ íƒìƒ‰ ì¤‘: {file_content.path}")
                        try:
                            dir_contents = repo.get_contents(file_content.path)
                            # ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°ì™€ ë‹¨ì¼ ê°ì²´ì¸ ê²½ìš° ëª¨ë‘ ì²˜ë¦¬
                            if isinstance(dir_contents, list):
                                contents.extend(dir_contents)
                            else:
                                contents.append(dir_contents)
                        except Exception as e:
                            print(f"ë””ë ‰í† ë¦¬ ë‚´ìš© ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜ ({file_content.path}): {str(e)}")
                    elif file_content.name.endswith(".py"):
                        python_files.append({
                            'name': file_content.name,
                            'path': file_content.path,
                            'url': file_content.html_url,
                            'sha': file_content.sha,
                            'size': file_content.size
                        })
                        print(f"íŒŒì´ì¬ íŒŒì¼ ë°œê²¬: {file_content.path}")
                except AttributeError:
                    # ê°€ë” ì½˜í…ì¸  ê°ì²´ê°€ ì˜ˆìƒëœ ì†ì„±ì„ ê°–ì§€ ì•ŠëŠ” ê²½ìš°ê°€ ìˆìŒ
                    print(f"ì½˜í…ì¸  ê°ì²´ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(file_content)}")
            
            print(f"{len(python_files)}ê°œì˜ íŒŒì´ì¬ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
            return python_files
            
        except RateLimitExceededException:
            reset_time = self.github.get_rate_limit().core.reset
            current_time = datetime.utcnow()
            wait_time = (reset_time - current_time).total_seconds()
            print(f"API ì‚¬ìš©ëŸ‰ ì œí•œ ì´ˆê³¼. {wait_time:.0f}ì´ˆ í›„ì— ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
            return []
        except Exception as e:
            print(f"íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {str(e)}")
            return []
    
    def download_file(self, repo_name, file_path):
        """
        GitHubì—ì„œ íŒŒì¼ ë‚´ìš© ë‹¤ìš´ë¡œë“œ
        
        Args:
            repo_name (str): ì €ì¥ì†Œ ì´ë¦„
            file_path (str): íŒŒì¼ ê²½ë¡œ
            
        Returns:
            str: íŒŒì¼ ë‚´ìš©
        """
        try:
            repo = self.github.get_repo(repo_name)
            file_content = repo.get_contents(file_path)
            
            if isinstance(file_content, list):
                return None  # ë””ë ‰í† ë¦¬ì¸ ê²½ìš°
            
            # base64ë¡œ ì¸ì½”ë”©ëœ ë‚´ìš© ë””ì½”ë”©
            content = base64.b64decode(file_content.content).decode('utf-8')
            return content
            
        except Exception as e:
            print(f"íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜ ({repo_name}/{file_path}): {str(e)}")
            return None
    
    def save_file(self, repo_name, file_path, content):
        """
        íŒŒì¼ ë‚´ìš©ì„ ë¡œì»¬ì— ì €ì¥
        
        Args:
            repo_name (str): ì €ì¥ì†Œ ì´ë¦„
            file_path (str): íŒŒì¼ ê²½ë¡œ
            content (str): íŒŒì¼ ë‚´ìš©
            
        Returns:
            str: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
        """
        if content is None:
            return None
            
        # ì €ì¥ ê²½ë¡œ ìƒì„± (ì›ë³¸ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìœ ì§€)
        repo_dir = os.path.join(self.output_dir, repo_name.replace('/', '_'))
        file_dir = os.path.dirname(file_path)
        save_dir = os.path.join(repo_dir, file_dir)
        os.makedirs(save_dir, exist_ok=True)
        
        # íŒŒì¼ ì´ë¦„ ì¶”ì¶œ ë° ì €ì¥
        file_name = os.path.basename(file_path)
        save_path = os.path.join(repo_dir, file_path)
        
        try:
            with open(save_path, 'w', encoding='utf-8') as f:
                f.write(content)
            return save_path
        except Exception as e:
            print(f"íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {str(e)}")
            return None
    
    def update_metadata(self, repo_info, file_info, local_path, quality_score=None):
        """
        ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
        
        Args:
            repo_info (dict): ì €ì¥ì†Œ ì •ë³´
            file_info (dict): íŒŒì¼ ì •ë³´
            local_path (str): ë¡œì»¬ ì €ì¥ ê²½ë¡œ
            quality_score (float, optional): ì½”ë“œ í’ˆì§ˆ ì ìˆ˜
        """
        try:
            with open(self.metadata_file, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
                
            # ìƒˆ ë©”íƒ€ë°ì´í„° í•­ëª© ì¶”ê°€
            metadata.append({
                'repo_name': repo_info['name'],
                'repo_full_name': repo_info['full_name'],
                'repo_url': repo_info['url'],
                'repo_stars': repo_info.get('stars', 0),
                'repo_license': repo_info.get('license', None),
                'file_name': file_info['name'],
                'file_path': file_info['path'],
                'file_url': file_info['url'],
                'local_path': local_path,
                'quality_score': quality_score,
                'downloaded_at': datetime.now().isoformat()
            })
            
            with open(self.metadata_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2)
                
        except Exception as e:
            print(f"ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {str(e)}")
    
    def crawl(self, query="language:python", max_repos=5, max_files_per_repo=None):
        """
        GitHubì—ì„œ íŒŒì´ì¬ ì½”ë“œ í¬ë¡¤ë§ ì‹¤í–‰ + í’ˆì§ˆ í‰ê°€
        
        Args:
            query (str): ê²€ìƒ‰ ì¿¼ë¦¬
            max_repos (int): ìµœëŒ€ ì €ì¥ì†Œ ìˆ˜
            max_files_per_repo (int, optional): ì €ì¥ì†Œë‹¹ ìµœëŒ€ íŒŒì¼ ìˆ˜ (Noneì´ë©´ ëª¨ë“  íŒŒì¼)
            
        Returns:
            list: ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ ì •ë³´ ëª©ë¡
        """
        # í’ˆì§ˆ í‰ê°€ ë„êµ¬ ì´ˆê¸°í™”
        quality_filter = CodeQualityFilter(metadata_file=self.metadata_file)

        # ì €ì¥ì†Œ ê²€ìƒ‰
        repositories = self.search_repositories(query=query, max_results=max_repos)
        downloaded_files = []

        for repo in repositories:
            print(f"\nì €ì¥ì†Œ ì²˜ë¦¬ ì¤‘: {repo['full_name']}")
            python_files = self.get_python_files(repo['full_name'], max_files=max_files_per_repo)

            for file_info in python_files:
                time.sleep(0.5)  # API ì œí•œ ë°©ì§€

                content = self.download_file(repo['full_name'], file_info['path'])
                if content:
                    local_path = self.save_file(repo['full_name'], file_info['path'], content)
                    if local_path:
                        # âœ… í’ˆì§ˆ ë¶„ì„ ìˆ˜í–‰
                        quality_score = quality_filter.evaluate_code_quality(local_path)
                        code_lines = quality_filter.count_code_lines(local_path)
                        complexity_info = quality_filter.check_code_complexity(local_path)
                        is_suitable, reason = quality_filter.is_suitable_for_learning(local_path, repo)

                        # ë©”íƒ€ë°ì´í„° ì €ì¥
                        self.update_metadata(
                            repo_info=repo,
                            file_info=file_info,
                            local_path=local_path,
                            quality_score=quality_score
                        )

                        # ğŸ‘‰ ë©”íƒ€ë°ì´í„°ì— ë¶€ê°€ ì •ë³´ ì§ì ‘ ì¶”ê°€
                        with open(self.metadata_file, 'r', encoding='utf-8') as f:
                            metadata = json.load(f)
                        if metadata:
                            metadata[-1]['code_lines'] = code_lines
                            metadata[-1]['complexity'] = complexity_info
                            metadata[-1]['is_suitable'] = is_suitable
                            metadata[-1]['unsuitable_reason'] = None if is_suitable else reason
                            with open(self.metadata_file, 'w', encoding='utf-8') as f:
                                json.dump(metadata, f, indent=2)

                        downloaded_files.append({
                            'repo': repo['full_name'],
                            'file': file_info['path'],
                            'local_path': local_path
                        })
                        print(f"íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë° í’ˆì§ˆ ë¶„ì„ ì™„ë£Œ: {file_info['path']}")

        print(f"\nì´ {len(downloaded_files)}ê°œì˜ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        return downloaded_files

    def crawl_repository(self, username, repo_name, max_files_per_repo=None):
        """
        íŠ¹ì • GitHub ì €ì¥ì†Œì—ì„œ ëª¨ë“  íŒŒì´ì¬ íŒŒì¼ì„ í¬ë¡¤ë§í•˜ê³  ì €ì¥

        Args:
            username (str): ì‚¬ìš©ì ì´ë¦„
            repo_name (str): ì €ì¥ì†Œ ì´ë¦„
            max_files_per_repo (int, optional): ìµœëŒ€ íŒŒì¼ ìˆ˜ (Noneì´ë©´ ëª¨ë“  íŒŒì¼)
        """
        full_name = f"{username}/{repo_name}"
        print(f"ğŸ” ì €ì¥ì†Œ {full_name} ì—ì„œ ì½”ë“œ í¬ë¡¤ë§ ì¤‘...")

        # ì €ì¥ì†Œ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ìƒì„¸ ì •ë³´ ì¶”ê°€)
        try:
            repo = self.github.get_repo(full_name)
            repo_info = {
                'name': repo.name,
                'full_name': repo.full_name,
                'url': repo.html_url,
                'description': repo.description,
                'stars': repo.stargazers_count,
                'forks': repo.forks_count,
                'created_at': repo.created_at.isoformat() if repo.created_at else '',
                'updated_at': repo.updated_at.isoformat() if repo.updated_at else '',
                'license': repo.license.name if repo.license else None
            }
        except Exception as e:
            print(f"ì €ì¥ì†Œ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {str(e)}")
            # ê¸°ë³¸ ì •ë³´ë¡œ ëŒ€ì²´
            repo_info = {
                'name': repo_name,
                'full_name': full_name,
                'url': f"https://github.com/{full_name}",
                'description': '',
                'stars': 0,
                'forks': 0,
                'created_at': '',
                'updated_at': '',
                'license': None
            }

        python_files = self.get_python_files(full_name, max_files=max_files_per_repo)
        downloaded_files = []
        total_files = len(python_files)
        
        print(f"ì´ {total_files}ê°œì˜ íŒŒì´ì¬ íŒŒì¼ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ë‹¤ìš´ë¡œë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")

        for i, file_info in enumerate(python_files):
            try:
                # ì§„í–‰ ìƒí™© í‘œì‹œ
                print(f"\rì§„í–‰ ì¤‘: {i+1}/{total_files} ({(i+1)/total_files*100:.1f}%)", end="")
                
                # API ì œí•œ ë°©ì§€ë¥¼ ìœ„í•œ ê°„ê²© ì¡°ì ˆ
                if i > 0 and i % 10 == 0:
                    time.sleep(2)
                
                content = self.download_file(full_name, file_info['path'])
                if content:
                    local_path = self.save_file(full_name, file_info['path'], content)
                    if local_path:
                        # í’ˆì§ˆ ë¶„ì„ ìˆ˜í–‰ (ì„ íƒì )
                        try:
                            quality_filter = CodeQualityFilter(metadata_file=self.metadata_file)
                            quality_score = quality_filter.evaluate_code_quality(local_path)
                            code_lines = quality_filter.count_code_lines(local_path)
                            complexity_info = quality_filter.check_code_complexity(local_path)
                            is_suitable, reason = quality_filter.is_suitable_for_learning(local_path, repo_info)
                        except Exception as e:
                            print(f"\ní’ˆì§ˆ ë¶„ì„ ì˜¤ë¥˜ ({file_info['path']}): {str(e)}")
                            quality_score = None
                            code_lines = 0
                            complexity_info = {}
                            is_suitable = None
                            reason = f"ë¶„ì„ ì˜¤ë¥˜: {str(e)}"
                        
                        # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
                        self.update_metadata(repo_info, file_info, local_path, quality_score)
                        
                        # í’ˆì§ˆ ë¶„ì„ ì •ë³´ ì¶”ê°€
                        with open(self.metadata_file, 'r', encoding='utf-8') as f:
                            metadata = json.load(f)
                        if metadata:
                            metadata[-1]['code_lines'] = code_lines
                            metadata[-1]['complexity'] = complexity_info
                            metadata[-1]['is_suitable'] = is_suitable
                            metadata[-1]['unsuitable_reason'] = None if is_suitable else reason
                            with open(self.metadata_file, 'w', encoding='utf-8') as f:
                                json.dump(metadata, f, indent=2)
                        
                        downloaded_files.append({
                            'repo': full_name,
                            'file': file_info['path'],
                            'local_path': local_path
                        })
            except Exception as e:
                print(f"\níŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({file_info['path']}): {str(e)}")

        print(f"\nâœ… ì €ì¥ì†Œ í¬ë¡¤ë§ ì™„ë£Œ: {len(downloaded_files)}ê°œì˜ íŒŒì¼ ë‹¤ìš´ë¡œë“œë¨")
        return downloaded_files

# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":
    # í¬ë¡¤ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    crawler = GitHubPythonCrawler(output_dir="collected_code")
    
    # ì „ì²´ ì €ì¥ì†Œ í¬ë¡¤ë§ (max_files_per_repo=Noneìœ¼ë¡œ ëª¨ë“  íŒŒì¼ ê°€ì ¸ì˜¤ê¸°)
    crawler.crawl(query="language:python stars:>1000", max_repos=1, max_files_per_repo=None)
    
    # ë˜ëŠ” íŠ¹ì • ì €ì¥ì†Œì˜ ëª¨ë“  íŒŒì´ì¬ íŒŒì¼ í¬ë¡¤ë§
    # crawler.crawl_repository("username", "repo_name", max_files_per_repo=None)